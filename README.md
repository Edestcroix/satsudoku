# Satsudoku
A sudoku SAT solver

## sud2sat
Converts a sudoku puzzle read from stdin into CNF format and outputs to stdout.
Can parse sudoku puzzles in any format where empty cells are denoted by a consistent character (e.g. `0`, `.`, or `_`), and cells are not separated by anything other than whitespace. `sud2sat` assumes the first non-digit character or `0` it encounters after stripping all whitespace is the empty cell character. Only 9x9 puzzles are supported. Since a large portion of the CNF encoding is identical for every sudoku puzzle, `sud2sat` looks for files containing this portion in `data/`, creating them if not found, and then concatenates them with the puzzle-specific CNF. This means that the first time `sud2sat` is run on a puzzle, it will take longer if `data/` is deleted.
## sat2sud
Converts the satisfiability output from `minisat`, read from stdin, into a solved sudoku puzzle.
Only 9x9 puzzles are supported. The input must be in the format output by `minisat` ran on a CNF file generated by `sud2sat`, and it must be a satisfying assignment. (i.e the starting sudoku puzzle had a solution) A solved puzzle will look like this:  

483 921 657  
967 345 821   
251 876 493   

548 132 976  
729 564 138   
136 798 245   
 
372 689 514   
814 253 769   
695 417 382  

## Benchmarking
The `benchmark` script encodes puzzles from `data/puzzles` into CNF form and and gathers benchmarking data from `minisat` solving these puzzles. It also optionally decodes the solutions from `minisat` into markdown tables and outputs them to files.
### Usage
-  `-s --silent` prevents printing to stdout.
- `-t=[] --test=[]` specify testing standard or hard puzzles, defaults to standard when not specified
- `-e=[] --enc=[]` specify the CNF encoding to use, will default to the minimal encoding when not specified. Can be either minimal, efficient, or extended. (e.g `-e=min` or `-e=extended`)
- `-a --all` tests all encodings with both standard and hard puzzles. Outputs results to `[output]` directory specified in the config.
- `-k --keep` keeps the CNF files generated by sud2sat and the solution encodings from `minisat`. By default, these files are deleted after `minisat` has finished solving them. These will be stored in the `[output]/encodings` and `[output]/solutions` directories, respectively.
- `-S --summarize` can only be used with `-a`. Outputs a summary of the benchmarking results which will contain the averages of the benchmarking results for each test and encoding type. The summary will be stored in the `[output]` directory specified in the config.
- `-d --decode` decodes the solution encodings from `minisat` into markdown tables and outputs them to `[output]/solutions`. Will output one solution for every solvable input puzzle.
- `-m --markdown` toggles formatting solved sudoku puzzles as markdown tables. This will only work if `-d` is specified.
- `-A --All` is `-a` with `-k -d -S -m` implicitly set, runs the full benchmarking suite, with all outputs generated for all test and encoding types. Inverts the behaviour of the other flags when they are specified alongside it, e.g. `-A -d` will generate all outputs except the decoded solutions, while `-d` will generate only the decoded solutions.
- `-c --clean` deletes all files in the `[output]` directory and exits immediately.
- `-h --help` prints the help message.

### Output
While benchmarks are running, CNF encodings for puzzles and solutions from `minisat` are output to the configured cache directory, which is deleted after benchmarking is complete unless the `-k` flag is specified, in which case the files are moved to the configured output directory.

The full layout of the output directory with all possible outputs is as follows:
```
[output]
├── encodings
│   ├── [encoding] (e.g. minimal)
│   │   ├── [test] (e.g. standard)
│   │   │   ├── sudoku_[num].cnf
│   │   │   └── ...
│   │   └── ...
│   └── sat
│       ├── [test]
│       │   ├── sudoku_[num].out
│       │   └── ...
│       └── ...
├── solutions
│   ├── [encoding]
│   │   ├── [test]
│   │   │   ├── sudoku_[num].[ext] (md or txt)
│   │   │   └── ...
│   │   └── ...
|   └── ...
├──  [num]-[test]-[encoding].md
|── ...
└──  summary.md
```
- `encodings` contains the CNF encodings for each puzzle and the solutions from `minisat` for each encoding. Each puzzle is re-encoded in all encoding types, but the satisfying assignment for each puzzle is the same regardless of encoding so only one solution is generated per puzzle, and is stored in the `sat` directory. 
- `solutions` contains the decoded solutions from `minisat` for each encoding.
- `[num]-[test]-[encoding].md` contains the benchmarking results for each encoding and test, numbered in the order they were run.
- `summary.md` contains the averages of the benchmarking results for each encoding and test.
- When only a single test is run, `test_results.md` is generated in place of the `[num]-[test]-[encoding].md` files. 

### Configuration
The configuration file is located at `config.json`. The following options are available:
- `resultsDir` is the directory where benchmarking results will be stored. Defaults to `benchmarks`.
- `puzzleDir` is the directory where puzzle files are stored. Defaults to `data/puzzles`.
- `cacheDir` is the directory where CNF encodings will be temporarily stored while benchmarking. Defaults to `.cache`.
- `round` is the number of decimal places to round benchmarking results to. Defaults to 2.
- `defaultPuzzleSet` specifies the default puzzle set to use when running `benchmark` with no arguments. Defaults to `standard`.
- `puzzleSets` for defining test parameters for puzzle sets. See below for more information.

### Custom Tests

Tests may be added by adding a new file containing puzzles to the `data/puzzles/` directory and configuring it in `config.json` by adding it to the `puzzles` array, with the key being the name of the test. A puzzle entry is of the following format:
```
"test_name": {
    "path": "path/to/puzzle/file",
    "numPuzzles": 100,
    "size": 9,
    "offset": 0
}
```
- `test_name` is the name of the test to be used as an identifier internally and in the output. Tests must have unique names.
- `path` is the path to the puzzle file, relative to the `puzzleDir` directory specified in `config.json`.
- `numPuzzles` is the number of puzzles in the file.
- `size` is how many lines the puzzle occupies in the file. This should be either 1 or 9, as any other way of storing puzzles has not been tested, and probably won't work. (I.e, 1-line puzzles have a full 9x9 sudoku puzzle but with no whitespace, and 9-line puzzles are a 9x9 sudoku puzzle with each row on a separate line.) 
- `offset` is the number of lines between the puzzles. Useful for puzzles that have a line between each puzzle, or puzzles that have a header line. Note that this is only lines between puzzles, not lines between rows of a puzzle. It is best to have 9-line puzzles formatted so that the 9 lines are sequential, with no lines in between; even though whitespace is ignored, unexpected behavior may occur if there are lines in between the rows, as the parser has not been tested with this format.

In theory, any set of 1-line or 9-line puzzles should work; the "medium" tests were added after the benchmarker was reworked to generalize over any puzzle sets and it worked without issue, but no other sets have been tested yet, so look out for potential bugs when adding puzzle sets.
  
## Dependencies
- python3.11 or later (may work with earlier versions, but has not been tested)
- [minisat](http://minisat.se/) (tested with version 2.2.1). The scripts in this repo just call `minisat` as a shell command, so it must be installed and available in `$PATH`
## Sources
Puzzles in /data/puzzles taken from:
- https://projecteuler.net/project/resources/p096_sudoku.txt

- http://magictour.free.fr/top95

- https://github.com/grantm/sudoku-exchange-puzzle-bank
